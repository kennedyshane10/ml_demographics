---
title: "Regularized Regression Life Insurance Example"
author: 'Shane Kennedy FSAI, FIA'
date: 'last updated: `r Sys.Date()`'
output:
  html_document:
    theme: journal
    toc: yes
    toc_float: yes
    toc_depth: 2
    number_sections: yes
    df_print: paged
  pdf_document:
    toc: yes
    toc_depth: '2'
  word_document:
    toc: yes
    reference_docx: word_styles_reference.docx
    toc_depth: 1
---


***
  
# Introduction  <a name="section1"></a>
  
***

## Objectives

* Fit a regularized regression model to a subset of the data set (training set) using LASSO with logistic regresssion
* Use the model to predict claims incidence rates and expected payouts on the hold out data (test set)

Many of the techniques applied in this document are described in 'Introduction to statistical learning with applications in R'
  
## Simulated data

Overview:

* A data set was simulated representing a block of insured lives for annually renewable group corporate life insurance business
* Member and claims data is provided from 2000 up to 2020
* Some simplifications are made e.g. assume that no members leave schemes during the year
* For illustrative purposes unknown continuous variables are added to the data set which have some correlation with other known variables.

Variable definitions:

* Age: Exact age of insured life at beginning of exposure year
* Sum Assured: Insurance coverage equal to two times salary
* Salary: Insured life's salary at beginning of exposure year
* Gender: M = Male, F = Female
* Occ: Occupation class. 1 = white collar/office workers, 2 = 50% office work/50% manual work, 3 = blue collar/manual work
* occ.desc: description of occupations
* Claim: Y = Claim occured during exposure year resulting in a payout of sum assured
* Location: Three locations of coverage (site 1, site 2, site 3)
* Smoker: 0 = non smoker, 1 = smoker 
* Compulsory: 0 = not compulsory for employee to become member of scheme, 1 = compulsory for employee to become member of scheme
* yrs_service: number of years service since joining the company
* vo2max: vo2max recorded for employee when they joined the company
* bmi: body max index recorded for employee when they joined the company
* var1 - var5: unknown continuous variables provided
 
***
 
# High level look at the data <a name="section2"></a>
  
***

## Install and load packages

```{r,warning = FALSE,message = FALSE}
start_time=Sys.time()

install_packages <- c("dplyr","glmnet","MASS","matrixcalc","corpcor","psych","data.table")
not_installed <- install_packages[which(!(install_packages %in% installed.packages()[,1]))]

if (length(not_installed > 0)){
  install.packages(not_installed)
}

library(dplyr)
library(glmnet)
library(MASS)
library(matrixcalc)
library(corpcor)
library(psych)
```

## Summary of data

```{r}
wd<-getwd()

source(paste0(wd,"/Simulate_data.R"))

life_insurance_data<-data.table::fread(paste0(wd,"/Life_Insurance_data.csv"))

str(life_insurance_data)
summary(life_insurance_data)

```

Here we can see the number of observations and variables.We also begin to develop an understanding of the variable types and distributions.

## Some data manipulation

* Remove some unnecessary columns
* Exclude occ and location for now
* Replace characters with numeric for Gender and Claim

```{r}
life_insurance_data<-life_insurance_data[,-c(1,6,8,19)]

data_adjusted<-life_insurance_data%>%
  mutate(gender=ifelse(life_insurance_data$gender=="M",0,1))%>%
  mutate(claim=ifelse(life_insurance_data$claim=="N",0,1))
```


## Look at correlations 

```{r}
mcor<-round(cor(data_adjusted),2)

lower<-mcor
lower[lower.tri(mcor)]<-""
lower<-as.data.frame(lower)
lower

psych::corPlot(data_adjusted)

data.table::fwrite(lower,paste0(wd,"/correlations.csv"))
```

Here we can see what variables have high (positive or negative) correlation with the dependent variable (claims).
It is clear that claims is highly correlated with smoker status.

We also see that many of the explanatory variables are highly correlated with one another (multicollinearity).For example, sum assured and salary, gender and var1, var3 and var1, vo2max and compulsory, gender and compulsory, age and sum assured/salary.

Multicollinearity can make fitted models more difficult to interpret. This can be mitigated by using regluarlization techniques such as the LASSO.

***
  
# Prepare data for modelling <a name="section3"></a>
  
***

## Specify x (explanatory variables) and y (dependent variable)

```{r}
x=model.matrix(claim ~.,life_insurance_data)
y=life_insurance_data$claim
```
    
## Split data into training and test sets #####

```{r}
set.seed(297)
train<-sample (1: nrow(x), floor(nrow(x)*0.8))
test<-(-train)
y_test<-y[test]
```

Here we are randomly splitting the data into training and test sets. A common split is 80/20.
It is also common to split the training set even further into training and validation (again using 80/20 is common) where the validation set is used to tune parameters. For simplicity I have not created a validation set here.

***
  
# Fit regularized regression model <a name="section4"></a>
  
***

## Use cross validation to choose lambda

* alpha = 1 indicates LASSO
* binomial family indicates logistic regression 
* type.measure deviance used as the cost function

Plot includes the cross-validation curve (red dotted line), and upper and lower standard deviation curves along the λ sequence (error bars). Two selected λ’s are indicated by the vertical dotted lines (see below).

```{r}
set.seed(1)
cv_lasso<-cv.glmnet(x[train,],y[train],alpha=1,family="binomial",type.measure = "deviance")
plot(cv_lasso)
bestlam_lasso<-cv_lasso$lambda.min
bestlam_lasso
log(bestlam_lasso)

cv_lasso$lambda.1se
log(cv_lasso$lambda.1se)
```



## Fit LASSO regression model on training data set using lambda.min 

We use the lambda chosen by cross validation i.e. lambda.min. This is the value of λ that gives minimum mean cross-validated error. The other λ saved is lambda.1se, which gives the most regularized model such that error is within one standard error of the minimum. To use that, we only need to replace lambda.min with lambda.1se above.
```{r}
model_lasso<-glmnet(x[train,],y[train],alpha=1,lambda=bestlam_lasso,family="binomial")
predict(model_lasso,type="coefficients",s=bestlam_lasso)
```

We see that in this example lambda.min tuning parameter does not shrink any coefficients to zero.

## Fit LASSO regression model on training data set using lambda.1se 

```{r}
model_lasso_1se<-glmnet(x[train,],y[train],alpha=1,lambda=cv_lasso$lambda.1se,family="binomial")
predict(model_lasso_1se,type="coefficients",s=cv_lasso$lambda.1se)
```

We see that in this example lambda.1se tuning parameter shrinks some coefficients to zero.

## Fit model on training data set using larger lambda 

```{r}
checklambda<-exp(-5)
model_lasso_check<-glmnet(x[train,],y[train],alpha=1,lambda=checklambda,family="binomial")

predict(model_lasso_check,type="coefficients",s=checklambda)
```

We see that in this example LASSO has shrunk many coefficients to zero since we have deliberately chosen a large lambda tuning parameter.

***

# Assess models' performance on test set <a name="section5"></a>

***

## Metrics for model fitted using lambda.min 

```{r}
assess<-assess.glmnet(model_lasso, newx=x[test,], newy = y[test])
assess

cnf <- confusion.glmnet(model_lasso, newx = x[test, ], newy = y[test])
print(cnf)
```
Confusion matrix above predicts if each member of the test data set claims or not based on their probability scores.
Threshold used above is 0.5. So if probability score is >0.5 claim is predicted, otherwise no claim predicted.


## Metrics for model fitted using lambda.1se 

```{r}
assess_1se<-assess.glmnet(model_lasso_1se, newx=x[test,], newy = y[test])
assess_1se

cnf_1se <- confusion.glmnet(model_lasso_1se, newx = x[test, ], newy = y[test])
print(cnf_1se)
```

## Metrics for model fitted using manually chosen lambda

```{r}
assess_check<-assess.glmnet(model_lasso_check, newx=x[test,], newy = y[test])
assess_check

cnf_check <- confusion.glmnet(model_lasso_check, newx = x[test, ], newy = y[test])
print(cnf_check)
```


## Get probabilities for test set using fitted models

To calculate the expected value of claims we use the probabilities generated by the models
We then calculate the actual risk cost and compare it to the expected risk cost for the test set using the different lambdas

Using lambda.min
```{r}
test_predictions<-predict(model_lasso,type="response",s=bestlam_lasso,newx=x[test,])%>%
  as_tibble()

names(test_predictions)[1] <- "probabilty"

test_actuals<-y[test]%>%
  as_tibble()

names(test_actuals)[1] <- "actuals"

test_actuals<-mutate(test_actuals,actuals=ifelse(test_actuals$actuals=="Y",1,0))

test_output<-cbind(x[test,],test_predictions,test_actuals)%>%
  mutate(actual_risk_cost=actuals*sum.assured)%>%
  mutate(expected_risk_cost=probabilty*sum.assured)

A<-sum(test_output$actual_risk_cost)
E<-sum(test_output$expected_risk_cost)
A
E
A/E

data.table:: fwrite(test_output,paste0(wd,"/test_output.csv"))

```

We then do the same using the model fitted with lambda.1se
```{r}
test_predictions_1se<-predict(model_lasso_1se,type="response",s=cv_lasso$lambda.1se,newx=x[test,])%>%
  as_tibble()

names(test_predictions_1se)[1] <- "probabilty"

test_actuals<-y[test]%>%
  as_tibble()

names(test_actuals)[1] <- "actuals"

test_actuals<-mutate(test_actuals,actuals=ifelse(test_actuals$actuals=="Y",1,0))

test_output_1se<-cbind(x[test,],test_predictions_1se,test_actuals)%>%
  mutate(actual_risk_cost=actuals*sum.assured)%>%
  mutate(expected_risk_cost=probabilty*sum.assured)

A<-sum(test_output_1se$actual_risk_cost)
E<-sum(test_output_1se$expected_risk_cost)
A
E
A/E

data.table:: fwrite(test_output_1se,paste0(wd,"/test_output_lambda_1se.csv"))

```

We then do the same using the model fitted with manually chosen lambda
```{r}
test_predictions_check<-predict(model_lasso_check,type="response",s=checklambda,newx=x[test,])%>%
  as_tibble()

names(test_predictions_check)[1] <- "probabilty"

test_actuals<-y[test]%>%
  as_tibble()

names(test_actuals)[1] <- "actuals"

test_actuals<-mutate(test_actuals,actuals=ifelse(test_actuals$actuals=="Y",1,0))

test_output_basic<-cbind(x[test,],test_predictions_check,test_actuals)%>%
  mutate(actual_risk_cost=actuals*sum.assured)%>%
  mutate(expected_risk_cost=probabilty*sum.assured)

A<-sum(test_output_basic$actual_risk_cost)
E<-sum(test_output_basic$expected_risk_cost)
A
E
A/E

data.table:: fwrite(test_output_basic,paste0(wd,"/test_output_larger_lambda.csv"))

```

We can see that the model fitted using lambda.min selects all of the 15 variables. This lambda coefficient minimizes the deviance function. 

The model fitted using lambda.1se ensures that the deviance function is within one standard error of the minimum.Some coefficients are shrunk to zero improving interpretability of the model. 

For the last model  we deliberately chose the lambda tuning parameter to be high and as a result fewer variables are selected. This model is obviously easier to interpret however the deviance function is higher. 

```{r}
end_time=Sys.time()

tot_time=end_time-start_time
tot_time
```

***
  
# Key considerations <a name="section6"></a>
  
***
* Understanding the business problem, for example
  + To support mortality experience analysis for reserving?
  + To support underwriting team when deciding what members require additional underwriting?
  + To support pricing team?
* Ethics and compliance 
  + Engage early with compliance team to ensure that required data can be collected in accordance with rules and regulations
  + Is there  risk that our model could result in exclusion of certain groups from coverage?
* Data quality and volume
  + May depend on the business problem
  + Will we have the variables chosen by the model for future business?
* Data architecture
  + For larger data sets (e.g. millions of rows, hundreds of variables) run time for glmnet may be too slow so other options may need to be considered such as Spark and H2O
  + Spark: https://therinspark.com/intro.html
  + H2O: https://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/glm.html
* Project structure 
  + CRISP DM: https://www.datascience-pm.com/crisp-dm-2/
* Communication
  + Rmarkdown: https://bookdown.org/yihui/rmarkdown/
  + ggplot: https://ggplot2.tidyverse.org/
  + Shiny: https://shiny.rstudio.com/
* Interpretability and accuracy 

***

# Further reading <a name="section7"></a>
  
***
* Logistic Regression for Insured Mortality Experience Studies:
  + SOA: https://www.soa.org/globalassets/assets/files/resources/essays-monographs/2014-living-to-100/mono-li14-2a-zhu.pdf
* LASSO modeling for mortality:
  + Gary Venter: http://www.garyventer.com/wp-content/uploads/2018/08/Venter-2018-Regularized-Age-Period-Cohort-Modeling-of-Opioid-Mortality-Rates-Preprint.pdf
* glmnet package: https://cran.r-project.org/web/packages/glmnet/vignettes/glmnet.pdf

***