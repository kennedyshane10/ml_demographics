---
title: "Regularized Regression Life Insurance Example"
author: 'Shane Kennedy FSAI, FIA'
date: 'last updated: `r Sys.Date()`'
output:
  html_document:
    theme: journal
    toc: yes
    toc_float: yes
    toc_depth: 2
    number_sections: yes
    df_print: paged
  pdf_document:
    toc: yes
    toc_depth: '2'
  word_document:
    toc: yes
    reference_docx: word_styles_reference.docx
    toc_depth: 1
---


***
  
# Introduction  <a name="section1"></a>
  
***

## Objectives

* Fit a regularized regression model to a subset of the data set (training set) using LASSO with logistic regresssion
* Use the model to predict claims incidence rates and expected payouts on the hold out data (test set)

Many of the techniques applied in this document are described in 'Introduction to statistical learning with applications in R'
  
## Simulated data

Overview:

* A data set was simulated representing a block of insured lives for annually renewable group corporate life insurance business
* Member and claims data is provided from 2000 up to 2020
* Some simplifications are made e.g. assume that no members leave schemes during the year
* For illustrative purposes unknown continuous variables are added to the data set which have some correlation with other known variables. These unknown variables could represent medical scores recorded at underwriting for example. 

Variable definitions:

* Age: Exact age of insured life at beginning of exposure year
* Sum Assured: Insurance coverage equal to two times salary
* Salary: Insured life's salary at beginning of exposure year
* Gender: M = Male, F = Female
* Occ: Occupation class. 1 = white collar/office workers, 2 = 50% office work/50% manual work, 3 = blue collar/manual work
* occ.desc: description of occupations
* Claim: Y = Claim occured during exposure year resulting in a payout of sum assured
* Location: Three locations of coverage (site 1, site 2, site 3)
* Smoker: 0 = non smoker, 1 = smoker 
* Compulsory: 0 = not compulsory for employee to become member of scheme, 1 = compulsory for employee to become member of scheme
* yrs_service: number of years service since joining the company
* vo2max: vo2max recorded for employee when they joined the company
* bmi: body max index recorded for employee when they joined the company
* var1 - var5: unknown continuous variables provided
 
***
 
# High level look at the data <a name="section2"></a>
  
***

## Load packages
```{r,warning = FALSE,message = FALSE}
start_time=Sys.time()
library(dplyr)
library(glmnet)
library(MASS)
library(matrixcalc)
library(corpcor)
```

## Summary of data

```{r}
life_insurance_data<-data.table::fread("C:/Users/Admin/Documents/R_projects/ml_demographics/Dataset/Life_Insurance_data.csv")

str(life_insurance_data)
summary(life_insurance_data)

```

Here we can see the number of observations and variables.We also begin to develop an understanding of the variable types and distributions.

## Some data manipulation

* Remove some unnecessary columns
* Exclude occ and location for now
* Replace characters with numeric for Gender and Claim

```{r}
life_insurance_data<-life_insurance_data[,-c(1,6,8,19)]

data_adjusted<-life_insurance_data%>%
  mutate(gender=ifelse(life_insurance_data$gender=="M",0,1))%>%
  mutate(claim=ifelse(life_insurance_data$claim=="N",0,1))
```


## Look at correlations 
```{r}
mcor<-round(cor(data_adjusted),2)

lower<-mcor
lower[lower.tri(mcor)]<-""
lower<-as.data.frame(lower)
lower

data.table::fwrite(lower,"C:/Users/Admin/Documents/R_projects/ml_demographics/Dataset/correlations.csv")
```

Here we can see what variables have high (positive or negative) correlation with the dependent variable (claims).
It is clear that claims is highly correlated with smoker status.

We also see that many of the explanatory variables are highly correlated with one another (multicollinearity).For example, sum assured and salary, gender and var1, var3 and var1, vo2max and compulsory, gender and compulsory, age and sum assured/salary.

Multicollinearity can make fitted models more difficult to interpret. This can be mitigated by using regluarlization techniques such as the LASSO.

***
  
# Prepare data for modelling <a name="section3"></a>
  
***

## Specify x (explanatory variables) and y (dependent variable)
```{r}
x=model.matrix(claim ~.,life_insurance_data)
y=life_insurance_data$claim
```
    
## Split data into training and test sets #####
```{r}
set.seed(297)
train<-sample (1: nrow(x), floor(nrow(x)*0.8))
test<-(-train)
y_test<-y[test]
```

Here we are randomly splitting the data into training and test sets. A common split is 80/20.
It is also common to split the training set even further into training and validation (again using 80/20 is common) where the validation set is used to tune parameters. For simplicity I have not created a validation set here.

***
  
# Fit regularized regression model <a name="section4"></a>
  
***

## Use cross validation to choose lambda

* alpha = 1 indicates LASSO
* binomial family indicates logistic regression 
* type.measure deviance used as the cost function

Plot includes the cross-validation curve (red dotted line), and upper and lower standard deviation curves along the λ sequence (error bars). Two selected λ’s are indicated by the vertical dotted lines (see below).

```{r}
set.seed(1)
cv_lasso<-cv.glmnet(x[train,],y[train],alpha=1,family="binomial",type.measure = "deviance")
plot(cv_lasso)
bestlam_lasso<-cv_lasso$lambda.min
bestlam_lasso
log(bestlam_lasso)

cv_lasso$lambda.1se
log(cv_lasso$lambda.1se)
```



## Fit LASSO regression model on training data set using lambda chosen by cross validation
We use the lambda chosen by cross validation i.e. lambda.min. This is the value of λ that gives minimum mean cross-validated error. The other λ saved is lambda.1se, which gives the most regularized model such that error is within one standard error of the minimum. To use that, we only need to replace lambda.min with lambda.1se above.
```{r}
model_lasso<-glmnet(x[train,],y[train],alpha=1,lambda=bestlam_lasso,family="binomial")
```

## Examine coefficients
```{r}
predict(model_lasso,type="coefficients",s=bestlam_lasso)
```

We see that LASSO has shrunk some of the coefficients to zero.

## Fit model on training data set using larger lambda for illustrative purposes
```{r}
checklambda<-exp(-3)
model_lasso_check<-glmnet(x[train,],y[train],alpha=1,lambda=checklambda,family="binomial")

predict(model_lasso_check,type="coefficients",s=checklambda)
```

We see that in this example LASSO has shrunk most of the coefficients to zero since we have deliberately chosen a large lambda tuning parameter.

***

# Assess models' performance on test set <a name="section5"></a>

***

## Some metrics for fitted model
```{r}
assess<-assess.glmnet(model_lasso, newx=x[test,], newy = y[test])
assess

cnf <- confusion.glmnet(model_lasso, newx = x[test, ], newy = y[test])
print(cnf)
```
Confusion matrix above predicts if each member of the test data set claims or not based on their probability scores.
Threshold used above is 0.5. So if probability score is >0.5 claim is predicted, otherwise no claim predicted.

## Some metrics for basic model with larger lambda for illustrative purposes
```{r}
assess_check<-assess.glmnet(model_lasso_check, newx=x[test,], newy = y[test])
assess_check

cnf_check <- confusion.glmnet(model_lasso_check, newx = x[test, ], newy = y[test])
print(cnf_check)
```
Confusion matrix above shows that the classifier predicts no claim in all cases and has a prediction accuracy of almost 93%!!
This highlights how we need to be careful when analyzing metrics.

## Get probabilities for test set using fitted models
To calculate the expected value of claims we use the probabilities generated by the models
We then calculate the actual risk cost and compare it to the expected risk cost for the test set using the lambda chosen by cv

```{r}
test_predictions<-predict(model_lasso,type="response",s=bestlam_lasso,newx=x[test,])%>%
  as_tibble()

names(test_predictions)[1] <- "probabilty"

test_actuals<-y[test]%>%
  as_tibble()

names(test_actuals)[1] <- "actuals"

test_actuals<-mutate(test_actuals,actuals=ifelse(test_actuals$actuals=="Y",1,0))

test_output<-cbind(x[test,],test_predictions,test_actuals)%>%
  mutate(actual_risk_cost=actuals*sum.assured)%>%
  mutate(expected_risk_cost=probabilty*sum.assured)

A<-sum(test_output$actual_risk_cost)
E<-sum(test_output$expected_risk_cost)
A
E
A/E

data.table:: fwrite(test_output,"C:/Users/Admin/Documents/R_projects/ml_demographics/Dataset/test_output.csv")

```

We then do the same using the basic model 
```{r}
test_predictions_check<-predict(model_lasso_check,type="response",s=checklambda,newx=x[test,])%>%
  as_tibble()

names(test_predictions_check)[1] <- "probabilty"

test_actuals<-y[test]%>%
  as_tibble()

names(test_actuals)[1] <- "actuals"

test_actuals<-mutate(test_actuals,actuals=ifelse(test_actuals$actuals=="Y",1,0))

test_output_basic<-cbind(x[test,],test_predictions_check,test_actuals)%>%
  mutate(actual_risk_cost=actuals*sum.assured)%>%
  mutate(expected_risk_cost=probabilty*sum.assured)

A<-sum(test_output_basic$actual_risk_cost)
E<-sum(test_output_basic$expected_risk_cost)
A
E
A/E

data.table:: fwrite(test_output,"C:/Users/Admin/Documents/R_projects/ml_demographics/Dataset/test_output_basic.csv")

```

We can see that the model fitted using cross validation to choose lambda selects 12 out of the 15 variables. For the test set this model can predict the expected claims value to almost within 2% of the actual claims amount.
The lambda coefficient chosen by cross validation is such that the deviance function is minimized. Some coefficients are shrunk to zero improving interpretability of the model. 

For the more basic model, where we deliberately chose the lambda tuning parameter to be high, only 2 variables are selected. This model is obviously easier to interpret however the deviance function is significantly higher. As a result, the expected claims value is 31% higher than the actual claims value for the test set demonstrating poor predictive power.

```{r}
end_time=Sys.time()

tot_time=end_time-start_time
tot_time
```

***
  
# Key considerations <a name="section6"></a>
  
***
* Understanding the business problem 
* Ethics and compliance 
* Data quality and volume
* Data architecture
  + Spark: https://therinspark.com/intro.html
  + H2O: https://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/glm.html
* Project structure 
  + CRISP DM: https://www.datascience-pm.com/crisp-dm-2/
* Communication
  + Rmarkdown: https://bookdown.org/yihui/rmarkdown/
  + ggplot: https://ggplot2.tidyverse.org/
  + Shiny: https://shiny.rstudio.com/
* Interpretability and accuracy 

***

# Further reading <a name="section7"></a>
  
***
* Logistic Regression for Insured Mortality Experience Studies:
  + SOA: https://www.soa.org/globalassets/assets/files/resources/essays-monographs/2014-living-to-100/mono-li14-2a-zhu.pdf
* glmnet package: https://cran.r-project.org/web/packages/glmnet/vignettes/glmnet.pdf

***